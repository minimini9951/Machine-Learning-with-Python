{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb59126",
   "metadata": {},
   "source": [
    "[ 문자처리 방식 ]\n",
    "- 토큰단위로 분리 \n",
    "- 더미\n",
    "- 0과1로 변환해서 처리 \n",
    "- 카운팅 기반을 가진 식 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14925b",
   "metadata": {},
   "source": [
    "# 필수 라이브러리 로딩  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57319358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:04:29.664658Z",
     "iopub.status.busy": "2022-11-16T05:04:29.664658Z",
     "iopub.status.idle": "2022-11-16T05:04:33.972057Z",
     "shell.execute_reply": "2022-11-16T05:04:33.972057Z",
     "shell.execute_reply.started": "2022-11-16T05:04:29.664658Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e34590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:04:33.972057Z",
     "iopub.status.busy": "2022-11-16T05:04:33.972057Z",
     "iopub.status.idle": "2022-11-16T05:04:34.068290Z",
     "shell.execute_reply": "2022-11-16T05:04:34.066370Z",
     "shell.execute_reply.started": "2022-11-16T05:04:33.972057Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family = 'D2coding')\n",
    "mpl.rc('axes', unicode_minus=False)\n",
    "\n",
    "sns.set(font=\"malgun gothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc('figure', figsize=(10, 8))\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e41984",
   "metadata": {},
   "source": [
    "# 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cbe148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:04:48.466851Z",
     "iopub.status.busy": "2022-11-16T05:04:48.465850Z",
     "iopub.status.idle": "2022-11-16T05:04:48.532945Z",
     "shell.execute_reply": "2022-11-16T05:04:48.531944Z",
     "shell.execute_reply.started": "2022-11-16T05:04:48.466851Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/k_digital/source/data/spam.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1b7a3",
   "metadata": {},
   "source": [
    "# 탐색적 데이터 분석 : EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe65959",
   "metadata": {},
   "source": [
    "## target : 목표변수 or 종속변수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2a1bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:04:50.655014Z",
     "iopub.status.busy": "2022-11-16T05:04:50.655014Z",
     "iopub.status.idle": "2022-11-16T05:04:50.675471Z",
     "shell.execute_reply": "2022-11-16T05:04:50.674515Z",
     "shell.execute_reply.started": "2022-11-16T05:04:50.655014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e9c03",
   "metadata": {},
   "source": [
    "- spam : 스팸문자 , pam : 일반문자 \n",
    "- NLTK(natural language toolkit) : 자연어 처리를 위해 만든 도구(패키지)\n",
    "- 주요기능 : 말뭉치, 토큰생성, 형태소 분석, 품사 태깅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ebcd6",
   "metadata": {},
   "source": [
    "## 말뭉치(corpus)\n",
    "- 자연어 분석을 위해 만든 샘플 문서 집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3b9a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:04:52.967687Z",
     "iopub.status.busy": "2022-11-16T05:04:52.967687Z",
     "iopub.status.idle": "2022-11-16T05:05:04.007057Z",
     "shell.execute_reply": "2022-11-16T05:05:04.005717Z",
     "shell.execute_reply.started": "2022-11-16T05:04:52.967687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('book')\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a123a35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:04.009461Z",
     "iopub.status.busy": "2022-11-16T05:05:04.008461Z",
     "iopub.status.idle": "2022-11-16T05:05:04.021620Z",
     "shell.execute_reply": "2022-11-16T05:05:04.021108Z",
     "shell.execute_reply.started": "2022-11-16T05:05:04.009461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gutenberg 말뭉치 : 저작권이 만료된 소설같은 작품들을 가지고 있는 문서 집합 \n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd56433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:07.255136Z",
     "iopub.status.busy": "2022-11-16T05:05:07.255136Z",
     "iopub.status.idle": "2022-11-16T05:05:07.274210Z",
     "shell.execute_reply": "2022-11-16T05:05:07.273208Z",
     "shell.execute_reply.started": "2022-11-16T05:05:07.255136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died t\n"
     ]
    }
   ],
   "source": [
    "shakespeare = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "print(shakespeare[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e8fa8e",
   "metadata": {},
   "source": [
    "## 토큰 생성 : 문자열을 가장 작은 단위인 토큰으로 나누는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1471c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:10.559302Z",
     "iopub.status.busy": "2022-11-16T05:05:10.559302Z",
     "iopub.status.idle": "2022-11-16T05:05:10.587232Z",
     "shell.execute_reply": "2022-11-16T05:05:10.585249Z",
     "shell.execute_reply.started": "2022-11-16T05:05:10.559302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a']\n"
     ]
    }
   ],
   "source": [
    "#from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(shakespeare[50:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8379759c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:11.950755Z",
     "iopub.status.busy": "2022-11-16T05:05:11.950755Z",
     "iopub.status.idle": "2022-11-16T05:05:11.966105Z",
     "shell.execute_reply": "2022-11-16T05:05:11.965101Z",
     "shell.execute_reply.started": "2022-11-16T05:05:11.950755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "# \\w : 영문자, 숫자, _(밑줄)\n",
    "re = RegexpTokenizer('[\\w]+')\n",
    "re.tokenize(shakespeare[50:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfea0",
   "metadata": {},
   "source": [
    "## 형태소(morpheme) 분석\n",
    "\n",
    "- 형태소 : 의미가 있는 가장 작은 말의 단위 \n",
    "- 형태소 분석 : 단어에서 어근, 접두사, 접미사, 품사 같은 속성을 파악하는 작업 \n",
    "- 기능\n",
    "    1. 어간 추출(stemming) : 단어의 기본형\n",
    "    2. 원형 복원(lemmatizing) : 같은 의미를 가진 여러 단어를 통합하는 작업\n",
    "    3. 품사 부착(Part-Of-Speech tagging,POS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa74a7b",
   "metadata": {},
   "source": [
    "[자주 사용하는 문자 클래스]\n",
    "[0-9] 또는 [a-zA-Z] 등은 무척 자주 사용하는 정규 표현식이다. 이렇게 자주 사용하는 정규식은 별도의 표기법으로 표현할 수 있다. 다음을 기억해 두자.\n",
    "\n",
    "\\d - 숫자와 매치, [0-9]와 동일한 표현식이다.\n",
    "\\D - 숫자가 아닌 것과 매치, [^0-9]와 동일한 표현식이다.\n",
    "\\s - whitespace 문자와 매치, [ \\t\\n\\r\\f\\v]와 동일한 표현식이다. 맨 앞의 빈 칸은 공백문자(space)를 의미한다.\n",
    "\\S - whitespace 문자가 아닌 것과 매치, [^ \\t\\n\\r\\f\\v]와 동일한 표현식이다.\n",
    "\\w - 문자+숫자(alphanumeric)와 매치, [a-zA-Z0-9_]와 동일한 표현식이다.\n",
    "\\W - 문자+숫자(alphanumeric)가 아닌 문자와 매치, [^a-zA-Z0-9_]와 동일한 표현식이다.\n",
    "대문자로 사용된 것은 소문자의 반대임을 추측할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498b7153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:14.188473Z",
     "iopub.status.busy": "2022-11-16T05:05:14.188473Z",
     "iopub.status.idle": "2022-11-16T05:05:14.205490Z",
     "shell.execute_reply": "2022-11-16T05:05:14.203466Z",
     "shell.execute_reply.started": "2022-11-16T05:05:14.188473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer :  ['fli', 'fli', 'fli', 'flew', 'flown']\n",
      "Lancaster Stemmer :  ['fly', 'fli', 'fly', 'flew', 'flown']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "\n",
    "st1 = PorterStemmer()\n",
    "st2 = LancasterStemmer()\n",
    "\n",
    "words = ['fly', 'flies', 'flying', 'flew', 'flown']\n",
    "\n",
    "    \n",
    "print('Porter Stemmer : ' , [st1.stem(w) for w in words])\n",
    "print('Lancaster Stemmer : ', [st2.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "559bac8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:07:21.498200Z",
     "iopub.status.busy": "2022-11-16T05:07:21.498200Z",
     "iopub.status.idle": "2022-11-16T05:07:21.559859Z",
     "shell.execute_reply": "2022-11-16T05:07:21.557855Z",
     "shell.execute_reply.started": "2022-11-16T05:07:21.498200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\minim/nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\share\\\\nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\minim\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\minim/nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\share\\\\nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\minim\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15668\\1264000372.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'v'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# pos는 품사 - 조금 더 정확하게 찾아주기 위해 !\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15668\\1264000372.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'v'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# pos는 품사 - 조금 더 정확하게 찾아주기 위해 !\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             )\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\deep\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\minim/nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\share\\\\nltk_data'\n    - 'C:\\\\Anaconda3\\\\envs\\\\deep\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\minim\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "[lm.lemmatize(w, pos = 'v') for w in words] # pos는 품사 - 조금 더 정확하게 찾아주기 위해 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e179a122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:39.884214Z",
     "iopub.status.busy": "2022-11-16T05:05:39.884214Z",
     "iopub.status.idle": "2022-11-16T05:05:39.908979Z",
     "shell.execute_reply": "2022-11-16T05:05:39.906980Z",
     "shell.execute_reply.started": "2022-11-16T05:05:39.884214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92dfb320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:40.317698Z",
     "iopub.status.busy": "2022-11-16T05:05:40.317698Z",
     "iopub.status.idle": "2022-11-16T05:05:40.461323Z",
     "shell.execute_reply": "2022-11-16T05:05:40.460326Z",
     "shell.execute_reply.started": "2022-11-16T05:05:40.317698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Emma', 'NNP'),\n",
       " ('Woodhouse', 'NNP'),\n",
       " (',', ','),\n",
       " ('handsome', 'NN'),\n",
       " (',', ','),\n",
       " ('clever', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('rich', 'JJ'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('comfortable', 'JJ'),\n",
       " ('home', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('happy', 'JJ'),\n",
       " ('disposition', 'NN'),\n",
       " (',', ','),\n",
       " ('seemed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('unite', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('blessings', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('existence', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "\n",
    "text = '''\n",
    "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
    "and happy disposition, seemed to unite some of the best blessings\n",
    "of existence\n",
    "'''\n",
    "\n",
    "# 품사를 붙이는 작업 <-- 단어 단위로 쪼개져있어야한다. \n",
    "tag_list = pos_tag(word_tokenize(text))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a131a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:42.300499Z",
     "iopub.status.busy": "2022-11-16T05:05:42.300499Z",
     "iopub.status.idle": "2022-11-16T05:05:42.322345Z",
     "shell.execute_reply": "2022-11-16T05:05:42.320610Z",
     "shell.execute_reply.started": "2022-11-16T05:05:42.300499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handsome', 'clever', 'home', 'disposition', 'existence']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_list = [t[0] for t in tag_list if t[1] == 'NN']\n",
    "nouns_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139acf3",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efa15f",
   "metadata": {},
   "source": [
    "## 특수문자(특수기호) 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a89b065d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:43.677724Z",
     "iopub.status.busy": "2022-11-16T05:05:43.677724Z",
     "iopub.status.idle": "2022-11-16T05:05:43.694089Z",
     "shell.execute_reply": "2022-11-16T05:05:43.692722Z",
     "shell.execute_reply.started": "2022-11-16T05:05:43.677724Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파이썬에 내장된 패키지 string는 문자열을 처리하는 다양한 함수를 제공한다. \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa2d0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:44.080061Z",
     "iopub.status.busy": "2022-11-16T05:05:44.080061Z",
     "iopub.status.idle": "2022-11-16T05:05:44.095087Z",
     "shell.execute_reply": "2022-11-16T05:05:44.094088Z",
     "shell.execute_reply.started": "2022-11-16T05:05:44.080061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특수기호 목록 확인 \n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3bbeab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:45.446151Z",
     "iopub.status.busy": "2022-11-16T05:05:45.446151Z",
     "iopub.status.idle": "2022-11-16T05:05:45.466065Z",
     "shell.execute_reply": "2022-11-16T05:05:45.464065Z",
     "shell.execute_reply.started": "2022-11-16T05:05:45.446151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5569    This is the 2nd time we have tried 2 contact u...\n",
       "5570                 Will 체 b going to esplanade fr home?\n",
       "5571    Pity, * was in mood for that. So...any other s...\n",
       "5572    The guy did some bitching but I acted like i'd...\n",
       "5573                           Rofl. Its true to its name\n",
       "Name: text, Length: 5574, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb918cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:46.624500Z",
     "iopub.status.busy": "2022-11-16T05:05:46.624500Z",
     "iopub.status.idle": "2022-11-16T05:05:46.647781Z",
     "shell.execute_reply": "2022-11-16T05:05:46.645799Z",
     "shell.execute_reply.started": "2022-11-16T05:05:46.624500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 문장을 가져와서 샘플에 담는다. \n",
    "sample = data['text'].loc[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df4415a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:46.916851Z",
     "iopub.status.busy": "2022-11-16T05:05:46.915852Z",
     "iopub.status.idle": "2022-11-16T05:05:46.930852Z",
     "shell.execute_reply": "2022-11-16T05:05:46.929851Z",
     "shell.execute_reply.started": "2022-11-16T05:05:46.916851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G\n",
      "o\n",
      " \n",
      "u\n",
      "n\n",
      "t\n",
      "i\n",
      "l\n",
      " \n",
      "j\n",
      "u\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "o\n",
      "i\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "c\n",
      "r\n",
      "a\n",
      "z\n",
      "y\n",
      ".\n",
      ".\n",
      " \n",
      "A\n",
      "v\n",
      "a\n",
      "i\n",
      "l\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "b\n",
      "u\n",
      "g\n",
      "i\n",
      "s\n",
      " \n",
      "n\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "e\n",
      " \n",
      "b\n",
      "u\n",
      "f\n",
      "f\n",
      "e\n",
      "t\n",
      ".\n",
      ".\n",
      ".\n",
      " \n",
      "C\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "g\n",
      "o\n",
      "t\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "a\n",
      "t\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in sample:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa66aff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:49.431621Z",
     "iopub.status.busy": "2022-11-16T05:05:49.431621Z",
     "iopub.status.idle": "2022-11-16T05:05:49.454130Z",
     "shell.execute_reply": "2022-11-16T05:05:49.452130Z",
     "shell.execute_reply.started": "2022-11-16T05:05:49.431621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G\n",
      "o\n",
      " \n",
      "u\n",
      "n\n",
      "t\n",
      "i\n",
      "l\n",
      " \n",
      "j\n",
      "u\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "o\n",
      "i\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "a\n",
      "z\n",
      "y\n",
      " \n",
      "A\n",
      "v\n",
      "a\n",
      "i\n",
      "l\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "b\n",
      "u\n",
      "g\n",
      "i\n",
      "s\n",
      " \n",
      "n\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "e\n",
      " \n",
      "b\n",
      "u\n",
      "f\n",
      "f\n",
      "e\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "g\n",
      "o\n",
      "t\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "a\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 제거 \n",
    "for i in sample:\n",
    "    if i not in string.punctuation:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6389eae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:49.705604Z",
     "iopub.status.busy": "2022-11-16T05:05:49.705604Z",
     "iopub.status.idle": "2022-11-16T05:05:49.719547Z",
     "shell.execute_reply": "2022-11-16T05:05:49.718534Z",
     "shell.execute_reply.started": "2022-11-16T05:05:49.705604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2178b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:50.537688Z",
     "iopub.status.busy": "2022-11-16T05:05:50.537688Z",
     "iopub.status.idle": "2022-11-16T05:05:50.560634Z",
     "shell.execute_reply": "2022-11-16T05:05:50.559651Z",
     "shell.execute_reply.started": "2022-11-16T05:05:50.537688Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G',\n",
       " 'o',\n",
       " ' ',\n",
       " 'u',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " ' ',\n",
       " 'j',\n",
       " 'u',\n",
       " 'r',\n",
       " 'o',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'p',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'c',\n",
       " 'r',\n",
       " 'a',\n",
       " 'z',\n",
       " 'y',\n",
       " ' ',\n",
       " 'A',\n",
       " 'v',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 'g',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'n',\n",
       " ' ',\n",
       " 'g',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'l',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'C',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 't']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = []\n",
    "for i in sample:\n",
    "    if i not in string.punctuation:\n",
    "        new_text.append(i)\n",
    "new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735bc6a",
   "metadata": {},
   "source": [
    "### join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67bd8d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:51.667678Z",
     "iopub.status.busy": "2022-11-16T05:05:51.667678Z",
     "iopub.status.idle": "2022-11-16T05:05:51.676778Z",
     "shell.execute_reply": "2022-11-16T05:05:51.676778Z",
     "shell.execute_reply.started": "2022-11-16T05:05:51.667678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연습\n",
    "s = ['a','p','p','l','e']\n",
    "''.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8f7f997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:52.118708Z",
     "iopub.status.busy": "2022-11-16T05:05:52.118708Z",
     "iopub.status.idle": "2022-11-16T05:05:52.131701Z",
     "shell.execute_reply": "2022-11-16T05:05:52.129698Z",
     "shell.execute_reply.started": "2022-11-16T05:05:52.118708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장형태로 합치기 \n",
    "new_sample = []\n",
    "for i in sample:\n",
    "    if i not in string.punctuation:\n",
    "        new_sample.append(i)\n",
    "new_sample = ''.join(new_sample)\n",
    "new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5157e2a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:52.552418Z",
     "iopub.status.busy": "2022-11-16T05:05:52.551419Z",
     "iopub.status.idle": "2022-11-16T05:05:52.567060Z",
     "shell.execute_reply": "2022-11-16T05:05:52.566060Z",
     "shell.execute_reply.started": "2022-11-16T05:05:52.552418Z"
    }
   },
   "outputs": [],
   "source": [
    "# 특수문자 제거하고 문장 만드는거 함수 \n",
    "def remove_punc(x):\n",
    "    new_sample = []\n",
    "    for i in x:\n",
    "        if i not in string.punctuation:\n",
    "            new_sample.append(i)\n",
    "    new_sample = ''.join(new_sample)\n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53e844f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:52.942041Z",
     "iopub.status.busy": "2022-11-16T05:05:52.942041Z",
     "iopub.status.idle": "2022-11-16T05:05:52.961231Z",
     "shell.execute_reply": "2022-11-16T05:05:52.959365Z",
     "shell.execute_reply.started": "2022-11-16T05:05:52.942041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c58e35cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:53.318537Z",
     "iopub.status.busy": "2022-11-16T05:05:53.317530Z",
     "iopub.status.idle": "2022-11-16T05:05:53.397651Z",
     "shell.execute_reply": "2022-11-16T05:05:53.397651Z",
     "shell.execute_reply.started": "2022-11-16T05:05:53.318537Z"
    }
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a0ae43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:53.639521Z",
     "iopub.status.busy": "2022-11-16T05:05:53.639521Z",
     "iopub.status.idle": "2022-11-16T05:05:53.661599Z",
     "shell.execute_reply": "2022-11-16T05:05:53.660599Z",
     "shell.execute_reply.started": "2022-11-16T05:05:53.639521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point crazy Available only in ...\n",
       "1    ham                            Ok lar Joking wif u oni\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb5db64",
   "metadata": {},
   "source": [
    "## 전처리 - 불용어(stopword)\n",
    "- 불용어 : 자연어 분석을 할 때 의미가 없는 단어 --> 제거하자\n",
    "- 불용어 사전 : nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9a69a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:54.318460Z",
     "iopub.status.busy": "2022-11-16T05:05:54.318460Z",
     "iopub.status.idle": "2022-11-16T05:05:54.341366Z",
     "shell.execute_reply": "2022-11-16T05:05:54.340353Z",
     "shell.execute_reply.started": "2022-11-16T05:05:54.318460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\minim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 목록 확인\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e97e2772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:54.668145Z",
     "iopub.status.busy": "2022-11-16T05:05:54.668145Z",
     "iopub.status.idle": "2022-11-16T05:05:54.703906Z",
     "shell.execute_reply": "2022-11-16T05:05:54.701940Z",
     "shell.execute_reply.started": "2022-11-16T05:05:54.668145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6145850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:55.017214Z",
     "iopub.status.busy": "2022-11-16T05:05:55.017214Z",
     "iopub.status.idle": "2022-11-16T05:05:55.042131Z",
     "shell.execute_reply": "2022-11-16T05:05:55.040232Z",
     "shell.execute_reply.started": "2022-11-16T05:05:55.017214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids() # 한국어가 없네 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e834b2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:55.408226Z",
     "iopub.status.busy": "2022-11-16T05:05:55.408226Z",
     "iopub.status.idle": "2022-11-16T05:05:55.417091Z",
     "shell.execute_reply": "2022-11-16T05:05:55.416092Z",
     "shell.execute_reply.started": "2022-11-16T05:05:55.408226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data['text'].loc[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99790137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:55.791440Z",
     "iopub.status.busy": "2022-11-16T05:05:55.791440Z",
     "iopub.status.idle": "2022-11-16T05:05:55.813815Z",
     "shell.execute_reply": "2022-11-16T05:05:55.811794Z",
     "shell.execute_reply.started": "2022-11-16T05:05:55.791440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'Available',\n",
       " 'only',\n",
       " 'in',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'Cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac1387b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:56.122097Z",
     "iopub.status.busy": "2022-11-16T05:05:56.121098Z",
     "iopub.status.idle": "2022-11-16T05:05:56.153513Z",
     "shell.execute_reply": "2022-11-16T05:05:56.152515Z",
     "shell.execute_reply.started": "2022-11-16T05:05:56.122097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      "crazy\n",
      "available\n",
      "bugis\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amore\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "# 소문자, 대문자 구분없게 하려고 lower\n",
    "for w in sample.split():\n",
    "    if w not in stopwords.words('english'):  # 불용어가 아니라면 \n",
    "        print(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c15f1c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:56.586210Z",
     "iopub.status.busy": "2022-11-16T05:05:56.586210Z",
     "iopub.status.idle": "2022-11-16T05:05:56.612285Z",
     "shell.execute_reply": "2022-11-16T05:05:56.611285Z",
     "shell.execute_reply.started": "2022-11-16T05:05:56.586210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sample = []\n",
    "for w in sample.split():\n",
    "    if w.lower() not in stopwords.words('english'):\n",
    "        new_sample.append(w.lower())\n",
    "        \n",
    "new_sample = ' '.join(new_sample)\n",
    "new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dde726c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:56.975402Z",
     "iopub.status.busy": "2022-11-16T05:05:56.975402Z",
     "iopub.status.idle": "2022-11-16T05:05:56.991576Z",
     "shell.execute_reply": "2022-11-16T05:05:56.991576Z",
     "shell.execute_reply.started": "2022-11-16T05:05:56.975402Z"
    }
   },
   "outputs": [],
   "source": [
    "def stop_words(x):\n",
    "    new_sample = []\n",
    "    for w in sample.split():\n",
    "        if w.lower() not in stopwords.words('english'):\n",
    "            new_sample.append(w.lower())\n",
    "\n",
    "    new_sample = ' '.join(new_sample)\n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7524c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:05:57.399319Z",
     "iopub.status.busy": "2022-11-16T05:05:57.399319Z",
     "iopub.status.idle": "2022-11-16T05:06:26.380359Z",
     "shell.execute_reply": "2022-11-16T05:06:26.379402Z",
     "shell.execute_reply.started": "2022-11-16T05:05:57.399319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point crazy available bugis n great ...\n",
       "1       go jurong point crazy available bugis n great ...\n",
       "2       go jurong point crazy available bugis n great ...\n",
       "3       go jurong point crazy available bugis n great ...\n",
       "4       go jurong point crazy available bugis n great ...\n",
       "                              ...                        \n",
       "5569    go jurong point crazy available bugis n great ...\n",
       "5570    go jurong point crazy available bugis n great ...\n",
       "5571    go jurong point crazy available bugis n great ...\n",
       "5572    go jurong point crazy available bugis n great ...\n",
       "5573    go jurong point crazy available bugis n great ...\n",
       "Name: text, Length: 5574, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(stop_words)\n",
    "data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb0d22",
   "metadata": {},
   "source": [
    "## 전처리 - 정형화 처리(target)\n",
    "- 이진분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764d820",
   "metadata": {},
   "source": [
    "### map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b53625b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:06:26.382459Z",
     "iopub.status.busy": "2022-11-16T05:06:26.382459Z",
     "iopub.status.idle": "2022-11-16T05:06:26.396412Z",
     "shell.execute_reply": "2022-11-16T05:06:26.394891Z",
     "shell.execute_reply.started": "2022-11-16T05:06:26.382459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    banana\n",
       "2     candy\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.Series(['a','b','c'])\n",
    "# map()\n",
    "# zip()\n",
    "sample.map({'a':'apple', 'b':'banana', 'c':'candy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d33c4d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:06:26.397314Z",
     "iopub.status.busy": "2022-11-16T05:06:26.397314Z",
     "iopub.status.idle": "2022-11-16T05:06:26.426076Z",
     "shell.execute_reply": "2022-11-16T05:06:26.425160Z",
     "shell.execute_reply.started": "2022-11-16T05:06:26.397314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5569    1\n",
       "5570    0\n",
       "5571    0\n",
       "5572    0\n",
       "5573    0\n",
       "Name: target, Length: 5574, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['target'].map({'spam':1, 'ham':0})\n",
    "data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ed464",
   "metadata": {},
   "source": [
    "## 카운트 기반의 벡터화 처리 \n",
    "\n",
    "- 카운트 기반 벡터화 : 문자를 개수 기반으로 벡터화하는 방식\n",
    "- 테이터 전체에 존재하는 모든 단어들을 사전처럼 모은 다음에 각각의 인덱스를 부여하고, \n",
    "- 문장마다 속한 단어가 있는 인덱스를 카운트하는 방식이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e138d",
   "metadata": {},
   "source": [
    "brown dog white cat brown bear : 0 (01 2)(02 1)\n",
    "<br>\n",
    "black dog "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40040c22",
   "metadata": {},
   "source": [
    "???????????????????/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12987ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:06:38.456484Z",
     "iopub.status.busy": "2022-11-16T05:06:38.456484Z",
     "iopub.status.idle": "2022-11-16T05:06:38.478826Z",
     "shell.execute_reply": "2022-11-16T05:06:38.476828Z",
     "shell.execute_reply.started": "2022-11-16T05:06:38.456484Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c45b60a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:06:38.762687Z",
     "iopub.status.busy": "2022-11-16T05:06:38.762687Z",
     "iopub.status.idle": "2022-11-16T05:06:38.889495Z",
     "shell.execute_reply": "2022-11-16T05:06:38.887496Z",
     "shell.execute_reply.started": "2022-11-16T05:06:38.762687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 6,\n",
       " 'jurong': 9,\n",
       " 'point': 11,\n",
       " 'crazy': 5,\n",
       " 'available': 1,\n",
       " 'bugis': 3,\n",
       " 'great': 8,\n",
       " 'world': 13,\n",
       " 'la': 10,\n",
       " 'buffet': 2,\n",
       " 'cine': 4,\n",
       " 'got': 7,\n",
       " 'amore': 0,\n",
       " 'wat': 12}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 객체 생성\n",
    "cv = CountVectorizer()\n",
    "# 모델 학습\n",
    "cv.fit(X)\n",
    "# 단어와 인덱스 출력\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c45529d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T05:06:39.157901Z",
     "iopub.status.busy": "2022-11-16T05:06:39.157901Z",
     "iopub.status.idle": "2022-11-16T05:06:39.282144Z",
     "shell.execute_reply": "2022-11-16T05:06:39.280656Z",
     "shell.execute_reply.started": "2022-11-16T05:06:39.157901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  :\t:\n",
      "  (5572, 3)\t1\n",
      "  (5572, 4)\t1\n",
      "  (5572, 5)\t1\n",
      "  (5572, 6)\t1\n",
      "  (5572, 7)\t1\n",
      "  (5572, 8)\t1\n",
      "  (5572, 9)\t1\n",
      "  (5572, 10)\t1\n",
      "  (5572, 11)\t1\n",
      "  (5572, 12)\t1\n",
      "  (5572, 13)\t1\n",
      "  (5573, 0)\t1\n",
      "  (5573, 1)\t1\n",
      "  (5573, 2)\t1\n",
      "  (5573, 3)\t1\n",
      "  (5573, 4)\t1\n",
      "  (5573, 5)\t1\n",
      "  (5573, 6)\t1\n",
      "  (5573, 7)\t1\n",
      "  (5573, 8)\t1\n",
      "  (5573, 9)\t1\n",
      "  (5573, 10)\t1\n",
      "  (5573, 11)\t1\n",
      "  (5573, 12)\t1\n",
      "  (5573, 13)\t1\n"
     ]
    }
   ],
   "source": [
    "X = cv.transform(X)\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
